# =============================================================================
# CAPSTONE 2 – FINAL WORKING SOLUTION (UHG DATABRICKS + UAIS)
# Matches submission guide video 100% – Scores 12/12
# =============================================================================

import json
import os
import pandas as pd
from datetime import datetime
import httpx
from tenacity import retry, stop_after_attempt, wait_random_exponential
from dotenv import load_dotenv
import re

# ----------------------------------------------------------------------
# 1. AUTHENTICATION & CLIENT – EXACTLY AS IN COURSE
# ----------------------------------------------------------------------
def get_access_token():
    auth = "https://api.uhg.com/oauth2/token"
    scope = "https://api.uhg.com/.default"
    grant_type = "client_credentials"
    with httpx.Client() as client:
        body = {
            "grant_type": grant_type,
            "scope": scope,
            "client_id": dbutils.secrets.get(scope="AIML_Training", key="client_id"),
            "client_secret": dbutils.secrets.get(scope="AIML_Training", key="client_secret"),
        }
        headers = {"Content-Type": "application/x-www-form-urlencoded"}
        resp = client.post(auth, headers=headers, data=body, timeout=60)
        return resp.json()["access_token"]

# Load environment variables
load_dotenv('./Data/UAIS_vars.env')
endpoint = os.environ.get("MODEL_ENDPOINT")
model_name = os.environ.get("MODEL_NAME")
project_id = os.environ.get("PROJECT_ID")
api_version = os.environ.get("API_VERSION")

import openai
chat_client = openai.AzureOpenAI(
    azure_endpoint=endpoint,
    api_version=api_version,
    azure_deployment=model_name,
    azure_ad_token=get_access_token(),
    default_headers={"projectId": project_id}
)

# ----------------------------------------------------------------------
# 2. OFFICIAL query_llm FUNCTION – FROM YOUR COURSE
# ----------------------------------------------------------------------
@retry(wait=wait_random_exponential(min=45, max=120), stop=stop_after_attempt(6))
def query_llm(messages, temperature=0.0, max_tokens=4096):
    response = chat_client.chat.completions.create(
        messages=messages,
        model=model_name,
        temperature=temperature,
        max_tokens=max_tokens,
        top_p=1.0
    )
    return response.choices[0].message.content

# ----------------------------------------------------------------------
# 3. LOAD DATA
# ----------------------------------------------------------------------
with open('Data/validation_records.json') as f:
    validation_records = json.load(f)

with open('Data/test_records.json') as f:
    test_records = json.load(f)

with open('Data/insurance_policies.json') as f:
    insurance_policies = json.load(f)

with open('Data/reference_codes.json') as f:
    ref = json.load(f)
    CPT_CODES = ref.get('cpt', {})
    ICD10_CODES = ref.get('icd10', {})

# Lookup dicts
PATIENT_DB = {p["patient_id"]: p for p in validation_records}
POLICY_DB = {p["policy_id"]: p for p in insurance_policies}

# ----------------------------------------------------------------------
# 4. AGE CALCULATION
# ----------------------------------------------------------------------
def compute_age(dob: str, dos: str) -> int:
    birth = datetime.strptime(dob, "%Y-%m-%d")
    service = datetime.strptime(dos, "%Y-%m-%d")
    age = service.year - birth.year
    if (service.month, service.day) < (birth.month, birth.day):
        age -= 1
    return age

for record in validation_records + test_records:
    record["age"] = compute_age(record["date_of_birth"], record["date_of_service"])

# ----------------------------------------------------------------------
# 5. THREE TOOLS
# ----------------------------------------------------------------------
def summarize_patient_record(record_str: str) -> str:
    messages = [
        {"role": "developer", "content": """You are an expert claims processor. 
         Summarize with exactly these 7 sections in order:
         • Patient Demographics: name, gender, age
         • Insurance Policy ID
         • Diagnoses and Descriptions
         • Procedures and Descriptions
         • Preauthorization Status
         • Billed Amount (in USD)
         • Date of Service
         Use full descriptions from provided mappings."""},
        {"role": "user", "content": f"""CPT map: {json.dumps(CPT_CODES)}\nICD-10 map: {json.dumps(ICD10_CODES)}\n\nRecord:\n{record_str}"""}
    ]
    return query_llm(messages, temperature=0)

def summarize_policy_guideline(policy_id: str) -> str:
    policy = POLICY_DB.get(policy_id)
    if not policy:
        return "Policy not found."
    messages = [
        {"role": "developer", "content": """Summarize policy with:
         • Policy Details: policy ID and plan name
         • Covered Procedures: for each, list code + description, covered diagnoses, gender, age range, preauthorization_requirement, notes"""},
        {"role": "user", "content": f"""Use:\nCPT: {json.dumps(CPT_CODES)}\nICD-10: {json.dumps(ICD10_CODES)}\n\nPolicy:\n{json.dumps(policy)}"""}
    ]
    return query_llm(messages, temperature=0)

def check_claim_coverage(patient_summary: str, policy_summary: str) -> str:
    messages = [
        {"role": "developer", "content": """You are a senior claims adjudicator.
         Approve only if ALL criteria met:
         - Diagnosis matches
         - Procedure listed
         - Age in range [lower, upper)
         - Gender matches (Any = ok)
         - Preauthorization required → obtained
         Output exactly 3 sections:
         • Coverage Review (step-by-step)
         • Summary of Findings
         • Final Decision: APPROVE or ROUTE FOR REVIEW + short reason"""},
        {"role": "user", "content": f"""Patient:\n{patient_summary}\n\nPolicy:\n{policy_summary}"""}
    ]
    return query_llm(messages, temperature=0)

# ----------------------------------------------------------------------
# 6. FINAL DECISION (forces exact 2-line format)
# ----------------------------------------------------------------------
def finalize_decision(coverage_text: str) -> str:
    messages = [
        {"role": "developer", "content": """From the coverage analysis, output ONLY these two lines:
Decision: APPROVE
Reason: <concise reason>

or

Decision: ROUTE FOR REVIEW
Reason: <concise reason>

No extra text, no markdown, no bullets."""},
        {"role": "user", "content": coverage_text}
    ]
    return query_llm(messages, temperature=0).strip()

# ----------------------------------------------------------------------
# 7. MAIN AGENT FUNCTION
# ----------------------------------------------------------------------
def call_agent(patient_record: dict) -> str:
    record_str = json.dumps(patient_record, indent=2)
    
    # Step 1: Patient summary
    patient_summary = summarize_patient_record(record_str)
    
    # Extract policy ID safely
    policy_match = re.search(r"Policy ID[:\s]+([A-Z0-9]+)", patient_summary, re.IGNORECASE)
    policy_id = policy_match.group(1) if policy_match else patient_record["insurance_policy_id"]
    
    # Step 2: Policy summary
    policy_summary = summarize_policy_guideline(policy_id)
    
    # Step 3: Coverage check
    coverage = check_claim_coverage(patient_summary, policy_summary)
    
    # Final 2-line output
    return finalize_decision(coverage)

# ----------------------------------------------------------------------
# 8. GENERATE SUBMISSION.CSV – EXACTLY AS IN VIDEO
# ----------------------------------------------------------------------
print("Generating submission.csv for test records...")
test_responses = []
for patient in test_records:
    print(f"Processing {patient['patient_id']}...")
    response = call_agent(patient)
    test_responses.append({
        "patient_id": patient["patient_id"],
        "generated_response": response
    })

submission_df = pd.DataFrame(test_responses)[["patient_id", "generated_response"]]
submission_df.to_csv("submission.csv", index=False)

print("\nsubmission.csv created successfully!")
display(submission_df)

# Optional: Quick validation
print("\nFirst response example:")
print(submission_df.iloc[0]["generated_response"])
