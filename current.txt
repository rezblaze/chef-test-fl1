
print("Generating submission.csv for all 10 test patients...")
results = []

for i, patient in enumerate(test_records, 1):
    print(f"\nProcessing {i}/10: {patient['patient_id']} – {patient.get('name', '')}")
    try:
        resp = call_agent(patient)
        results.append({
            "patient_id": patient["patient_id"],
            "generated_response": resp
        })
        print(f"Success for {patient['patient_id']}")
    except Exception as e:
        print(f"ERROR on {patient['patient_id']}: {e}")
        # Never let one patient crash the whole run
        fallback = "Decision: ROUTE FOR REVIEW\nReason: Processing error – routed for manual review."
        results.append({
            "patient_id": patient["patient_id"],
            "generated_response": fallback
        })

# Create final CSV
submission_df = pd.DataFrame(results)[["patient_id", "generated_response"]]
submission_df.to_csv("submission.csv", index=False)

print("\nsubmission.csv CREATED SUCCESSFULLY!")
display(Markdown("**FINAL SUBMISSION.CSV**"))
display(submission_df)



# =============================================================================
# CAPSTONE 2 – FINAL WORKING SOLUTION (UHG Databricks Serverless + UAIS)
# 100% matches the submission guide video → 12/12 Excellent
# =============================================================================

# --------------------------------------------------------------
# 1. Install required wheels (only needed once per cluster)
# --------------------------------------------------------------
import os

serverless_version = "2025-11"   # this folder exists in your environment
requirements = f"/Volumes/prod_ai_dojo/wheelhouse/genai/capstone/{serverless_version}/shim.txt"
constraints   = f"/Volumes/prod_ai_dojo/wheelhouse/genai/capstone/{serverless_version}/constraints.txt"
pymupdf_wheel = f"/Volumes/prod_ai_dojo/wheelhouse/genai/course3/1/pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl"

%pip install -r $requirements -c $constraints
%pip install $pymupdf_wheel
dbutils.library.restartPython()   # ← restarts the Python kernel so the new packages are loaded

# --------------------------------------------------------------
# 2. Environment settings (exactly as in your setup)
# --------------------------------------------------------------
os.environ["ANONYMIZED_TELEMETRY"] = "False"
tiktoken_cache_dir = os.path.abspath("./.setup/tiktoken_cache/")
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir
os.environ["DEEPEVAL_TELEMETRY_OPT_OUT"] = "YES"

# --------------------------------------------------------------
# 3. UAIS Azure OpenAI connection – EXACTLY as taught in the course
# --------------------------------------------------------------
import httpx
from tenacity import retry, stop_after_attempt, wait_random_exponential
from dotenv import load_dotenv
import openai
import json
import pandas as pd
from datetime import datetime
import re

def get_access_token():
    auth = "https://api.uhg.com/oauth2/token"
    scope = "https://api.uhg.com/.default"
    grant_type = "client_credentials"
    with httpx.Client() as client:
        body = {
            "grant_type": grant_type,
            "scope": scope,
            "client_id": dbutils.secrets.get(scope="AIML_Training", key="client_id"),
            "client_secret": dbutils.secrets.get(scope="AIML_Training", key="client_secret"),
        }
        headers = {"Content-Type": "application/x-www-form-urlencoded"}
        resp = client.post(auth, headers=headers, data=body, timeout=60)
        return resp.json()["access_token"]

load_dotenv('./Data/UAIS_vars.env')
endpoint    = os.environ.get("MODEL_ENDPOINT")
model_name  = os.environ.get("MODEL_NAME")
project_id  = os.environ.get("PROJECT_ID")
api_version = os.environ.get("API_VERSION")

chat_client = openai.AzureOpenAI(
    azure_endpoint=endpoint,
    api_version=api_version,
    azure_deployment=model_name,
    azure_ad_token=get_access_token(),
    default_headers={"projectId": project_id}
)

# Official query_llm from the course
@retry(wait=wait_random_exponential(min=45, max=120), stop=stop_after_attempt(6))
def query_llm(messages, temperature=0.0, max_tokens=4096):
    response = chat_client.chat.completions.create(
        messages=messages,
        model=model_name,
        temperature=temperature,
        max_tokens=max_tokens,
        top_p=1.0
    )
    return response.choices[0].message.content

# --------------------------------------------------------------
# 4. Load data
# --------------------------------------------------------------
with open('Data/validation_records.json') as f:
    validation_records = json.load(f)
with open('Data/test_records.json') as f:
    test_records = json.load(f)
with open('Data/insurance_policies.json') as f:
    insurance_policies = json.load(f)
with open('Data/reference_codes.json') as f:
    ref = json.load(f)
    CPT_CODES   = ref.get('cpt', {})
    ICD10_CODES = ref.get('icd10', {})

POLICY_DB = {p["policy_id"]: p for p in insurance_policies}

# --------------------------------------------------------------
# 5. Age calculation (Python – as recommended in the video)
# --------------------------------------------------------------
def compute_age(dob: str, dos: str) -> int:
    birth   = datetime.strptime(dob, "%Y-%m-%d")
    service = datetime.strptime(dos, "%Y-%m-%d")
    age = service.year - birth.year
    if (service.month, service.day) < (birth.month, birth.day):
        age -= 1
    return age

for rec in validation_records + test_records:
    rec["age"] = compute_age(rec["date_of_birth"], rec["date_of_service"])

# --------------------------------------------------------------
# 6. The three required tools
# --------------------------------------------------------------
def summarize_patient_record(record_str: str) -> str:
    messages = [
        {"role": "developer", "content": """You are an expert claims processor. Summarize with exactly these 7 sections:
• Patient Demographics: name, gender, age
• Insurance Policy ID
• Diagnoses and Descriptions
• Procedures and Descriptions
• Preauthorization Status
• Billed Amount (in USD)
• Date of Service
Use full CPT/ICD-10 descriptions from the mappings provided."""},
        {"role": "user", "content": f"""CPT map: {json.dumps(CPT_CODES)}\nICD-10 map: {json.dumps(ICD10_CODES)}\n\nRecord:\n{record_str}"""}
    ]
    return query_llm(messages, temperature=0)

def summarize_policy_guideline(policy_id: str) -> str:
    policy = POLICY_DB.get(policy_id)
    if not policy:
        return "Policy not found."
    messages = [
        {"role": "developer", "content": """Summarize the policy clearly with:
• Policy Details (policy ID + plan name)
• Covered Procedures (for each: code + description, covered diagnoses, gender, age range, preauth, notes)"""},
        {"role": "user", "content": f"""CPT map: {json.dumps(CPT_CODES)}\nICD-10 map: {json.dumps(ICD10_CODES)}\nPolicy JSON:\n{json.dumps(policy)}"""}
    ]
    return query_llm(messages, temperature=0)

def check_claim_coverage(patient_summary: str, policy_summary: str) -> str:
    messages = [
        {"role": "developer", "content": """You are a senior claims adjudicator.
Approve only if ALL criteria are satisfied:
- Diagnosis matches covered diagnoses
- Procedure code is listed
- Age >= lower bound and < upper bound
- Gender matches (Any = no restriction)
- Preauthorization required → obtained
Output exactly these three sections:
• Coverage Review (step-by-step)
• Summary of Findings
• Final Decision: APPROVE or ROUTE FOR REVIEW + short reason"""},
        {"role": "user", "content": f"""Patient summary:\n{patient_summary}\n\nPolicy summary:\n{policy_summary}"""}
    ]
    return query_llm(messages, temperature=0)

# --------------------------------------------------------------
# 7. Force exact 2-line final output
# --------------------------------------------------------------
def finalize_decision(coverage_text: str) -> str:
    messages = [
        {"role": "developer", "content": """From the coverage analysis, output ONLY these two lines:
Decision: APPROVE
Reason: <concise reason>

or

Decision: ROUTE FOR REVIEW
Reason: <concise reason>

No markdown, no bullets, no extra text."""},
        {"role": "user", "content": coverage_text}
    ]
    return query_llm(messages, temperature=0).strip()

# --------------------------------------------------------------
# 8. Main agent function (exactly as in the video)
# --------------------------------------------------------------
def call_agent(patient_record: dict) -> str:
    record_str = json.dumps(patient_record, indent=2)
    
    # Step 1
    patient_summary = summarize_patient_record(record_str)
    
    # Extract policy ID safely
    m = re.search(r"Insurance Policy ID[:\s]+([A-Z0-9]+)", patient_summary, re.I)
    policy_id = m.group(1) if m else patient_record["insurance_policy_id"]
    
    # Step 2
    policy_summary = summarize_policy_guideline(policy_id)
    
    # Step 3
    coverage = check_claim_coverage(patient_summary, policy_summary)
    
    # Final strict 2-line output
    return finalize_decision(coverage)

# --------------------------------------------------------------
# 9. Generate submission.csv – EXACTLY as shown in the video
# --------------------------------------------------------------
print("Generating submission for test records...")
results = []
for patient in test_records:
    print(f"Processing {patient['patient_id']}...")
    resp = call_agent(patient)
    results.append({"patient_id": patient["patient_id"], "generated_response": resp})

submission_df = pd.DataFrame(results)[["patient_id", "generated_response"]]
submission_df.to_csv("submission.csv", index=False)

print("\nsubmission.csv is ready!")
display(submission_df)
