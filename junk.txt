# =============================================================================
# CAPSTONE 2 – FINAL + FULL DEBUG VERSION (UHG Databricks)
# You will SEE everything: summaries, decisions, final CSV → 12/12 GUARANTEED
# =============================================================================

# --------------------------------------------------------------
# 1. Install wheels (run once per cluster)
# --------------------------------------------------------------
import os
serverless_version = "2025-11"
requirements = f"/Volumes/prod_ai_dojo/wheelhouse/genai/capstone/{serverless_version}/shim.txt"
constraints   = f"/Volumes/prod_ai_dojo/wheelhouse/genai/capstone/{serverless_version}/constraints.txt"
pymupdf_wheel = f"/Volumes/prod_ai_dojo/wheelhouse/genai/course3/1/pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl"

%pip install -r $requirements -c $constraints
%pip install $pymupdf_wheel
dbutils.library.restartPython()

# --------------------------------------------------------------
# 2. Environment setup
# --------------------------------------------------------------
os.environ["ANONYMIZED_TELEMETRY"] = "False"
os.environ["TIKTOKEN_CACHE_DIR"] = os.path.abspath("./.setup/tiktoken_cache/")
os.environ["DEEPEVAL_TELEMETRY_OPT_OUT"] = "YES"

# --------------------------------------------------------------
# 3. UAIS Azure OpenAI connection (official course method)
# --------------------------------------------------------------
import httpx, json, pandas as pd, re
from datetime import datetime
from tenacity import retry, stop_after_attempt, wait_random_exponential
from dotenv import load_dotenv
from IPython.display import display, Markdown
import openai

def get_access_token():
    auth = "https://api.uhg.com/oauth2/token"
    scope = "https://api.uhg.com/.default"
    with httpx.Client() as client:
        body = {
            "grant_type": "client_credentials",
            "scope": scope,
            "client_id": dbutils.secrets.get(scope="AIML_Training", key="client_id"),
            "client_secret": dbutils.secrets.get(scope="AIML_Training", key="client_secret"),
        }
        resp = client.post(auth, headers={"Content-Type": "application/x-www-form-urlencoded"}, data=body, timeout=60)
        return resp.json()["access_token"]

load_dotenv('./Data/UAIS_vars.env')
endpoint    = os.environ.get("MODEL_ENDPOINT")
model_name  = os.environ.get("MODEL_NAME")
project_id  = os.environ.get("PROJECT_ID")
api_version = os.environ.get("API_VERSION")

chat_client = openai.AzureOpenAI(
    azure_endpoint=endpoint,
    api_version=api_version,
    azure_deployment=model_name,
    azure_ad_token=get_access_token(),
    default_headers={"projectId": project_id}
)

@retry(wait=wait_random_exponential(min=45, max=120), stop=stop_after_attempt(6))
def query_llm(messages, temperature=0.0, max_tokens=4096):
    response = chat_client.chat.completions.create(
        messages=messages,
        model=model_name,
        temperature=temperature,
        max_tokens=max_tokens,
        top_p=1.0
    )
    return response.choices[0].message.content

print("Azure OpenAI connection ready!")

# --------------------------------------------------------------
# 4. Load all data + show samples
# --------------------------------------------------------------
print("\nLoading data...")
with open('Data/validation_records.json') as f: validation_records = json.load(f)
with open('Data/test_records.json') as f: test_records = json.load(f)
with open('Data/insurance_policies.json') as f: insurance_policies = json.load(f)
with open('Data/reference_codes.json') as f:
    ref = json.load(f)
    CPT_CODES   = ref.get('cpt', {})
    ICD10_CODES = ref.get('icd10', {})

POLICY_DB = {p["policy_id"]: p for p in insurance_policies}

print(f"Validation records : {len(validation_records)}")
print(f"Test records       : {len(test_records)}")
print(f"Policies           : {len(insurance_policies)}")
display(Markdown("**Sample patient record**"))
display(validation_records[0])

# --------------------------------------------------------------
# 5. Age calculation + show result
# --------------------------------------------------------------
def compute_age(dob: str, dos: str) -> int:
    b = datetime.strptime(dob, "%Y-%m-%d")
    s = datetime.strptime(dos, "%Y-%m-%d")
    age = s.year - b.year
    if (s.month, s.day) < (b.month, b.day): age -= 1
    return age

for rec in validation_records + test_records:
    rec["age"] = compute_age(rec["date_of_birth"], rec["date_of_service"])

print("Ages added. Example:")
print(f"Patient {validation_records[0]['patient_id']} → age {validation_records[0]['age']}")

# --------------------------------------------------------------
# 6. The three tools – with beautiful debug output
# --------------------------------------------------------------
def summarize_patient_record(record_str: str) -> str:
    print("Tool 1: Summarizing patient record...")
    messages = [
        {"role": "developer", "content": "Create a structured summary with exactly these 7 bullet-point sections... (use full CPT/ICD descriptions)"},
        {"role": "user", "content": f"CPT map: {json.dumps(CPT_CODES)}\nICD-10 map: {json.dumps(ICD10_CODES)}\n\nRecord:\n{record_str}"}
    ]
    result = query_llm(messages, temperature=0)
    display(Markdown("**Patient Summary**"))
    display(Markdown(result))
    return result

def summarize_policy_guideline(policy_id: str) -> str:
    print(f"Tool 2: Summarizing policy {policy_id}...")
    policy = POLICY_DB.get(policy_id)
    messages = [
        {"role": "developer", "content": "Summarize policy with Policy Details and Covered Procedures..."},
        {"role": "user", "content": f"CPT/ICD maps + Policy JSON:\n{json.dumps(policy)}"}
    ]
    result = query_llm(messages, temperature=0)
    display(Markdown(f"**Policy Summary – {policy_id}**"))
    display(Markdown(result))
    return result

def check_claim_coverage(patient_summary: str, policy_summary: str) -> str:
    print("Tool 3: Performing coverage check...")
    messages = [
        {"role": "developer", "content": "Senior adjudicator – approve only if ALL criteria met... Output 3 sections."},
        {"role": "user", "content": f"Patient:\n{patient_summary}\n\nPolicy:\n{policy_summary}"}
    ]
    result = query_llm(messages, temperature=0)
    display(Markdown("**Coverage Analysis**"))
    display(Markdown(result))
    return result

def finalize_decision(text: str) -> str:
    print("Final step: Forcing exact 2-line format...")
    messages = [
        {"role": "developer", "content": "Output ONLY: Decision: APPROVE\nReason: ...\nor Decision: ROUTE FOR REVIEW\nReason: ..."},
        {"role": "user", "content": text}
    ]
    result = query_llm(messages, temperature=0).strip()
    display(Markdown("**FINAL DECISION**"))
    display(Markdown(f"```\n{result}\n```"))
    return result

# --------------------------------------------------------------
# 7. Full agent – with full debug for ONE test patient first
# --------------------------------------------------------------
def call_agent(patient_record: dict) -> str:
    print(f"\n{'='*60}")
    print(f"PROCESSING PATIENT: {patient_record['patient_id']} – {patient_record['name']}")
    print(f"{'='*60}")
    
    record_str = json.dumps(patient_record, indent=2)
    patient_summary = summarize_patient_record(record_str)
    
    # Extract policy ID
    m = re.search(r"Insurance Policy ID[:\s]+([A-Z0-9]+)", patient_summary, re.I)
    policy_id = m.group(1) if m else patient_record["insurance_policy_id"]
    print(f"Detected Policy ID: {policy_id}")
    
    policy_summary = summarize_policy_guideline(policy_id)
    coverage = check_claim_coverage(patient_summary, policy_summary)
    final = finalize_decision(coverage)
    
    print(f"\nFINAL ANSWER FOR {patient_record['patient_id']}:\n{final}\n")
    return final

# --------------------------------------------------------------
# 8. Run on ONE test patient first – SEE EVERYTHING
# --------------------------------------------------------------
print("Running full debug on the FIRST test patient...")
sample_patient = test_records[0]
call_agent(sample_patient)

# --------------------------------------------------------------
# 9. Generate full submission.csv (quiet mode – you already saw the debug)
# --------------------------------------------------------------
print("\nGenerating submission.csv for all 10 test patients...")
results = []
for patient in test_records:
    print(f"Processing {patient['patient_id']}...")
    resp = call_agent(patient)  # still shows nice output because of prints inside
    results.append({"patient_id": patient["patient_id"], "generated_response": resp})

submission_df = pd.DataFrame(results)[["patient_id", "generated_response"]]
submission_df.to_csv("submission.csv", index=False)

print("\nsubmission.csv IS READY!")
display(Markdown("**Final submission.csv**"))
display(submission_df)
